{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¶ Requesting Predictions from the Feast Model  \n",
    "\n",
    "Now that we have our features, it's time to **make predictions** using a deployed model. We'll send song data to an inference endpoint and receive predictions in return. This process helps us understand how our model interprets the features weâ€™ve defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“¥ Setting Up Dependencies  \n",
    "\n",
    "Before making predictions, we need to **import the necessary libraries** to handle data, timestamps, and API requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Defining the Inference Endpoint  \n",
    "\n",
    "To interact with our deployed model, we define the **model name** (e.g., `\"jukebox\"`) and the **inference API endpoint** for sending requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "deployed_model_name = \"jukebox\"\n",
    "infer_endpoint = \"<paste-the-link-here>\"\n",
    "infer_url = f\"{infer_endpoint}/v2/models/{deployed_model_name}/infer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽµ Selecting a Song for Prediction  \n",
    "\n",
    "To test our model, we first need to choose a **specific song** from our dataset. We start by loading a **preprocessed dataset** containing various song features. \n",
    "\n",
    "From this dataset, we filter out a particular songâ€”such as `\"Not Like Us\"`â€”to use as our test case. Once we have our selected song, we extract its **Spotify ID**, which serves as the unique identifier for our model input. \n",
    "\n",
    "This allows us to send the correct data to our inference system and obtain a meaningful prediction for a song we recognize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "song_properties = pd.read_parquet('../99-data_prep/song_properties.parquet')\n",
    "favorite_song = song_properties.loc[song_properties[\"name\"]==\"Not Like Us\"]\n",
    "favorite_song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ Sending a Prediction Request  \n",
    "\n",
    "Once we have selected our song, we need to send its **Spotify ID** to the model for inference. \n",
    "\n",
    "To do this, we define a function that formats the input data into the correct **JSON structure** expected by the model. This function then sends an **HTTP request** to the inference endpoint, where the model processes the request and returns a prediction. \n",
    "\n",
    "Finally, we extract the **modelâ€™s response**, giving us the predicted outcome for the selected song. This step seamlessly connects our **Feast-managed features** with real-time machine learning predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def rest_request(data):\n",
    "    json_data = {\n",
    "        \"inputs\": [\n",
    "            {\n",
    "                \"name\": \"input\",\n",
    "                \"shape\": [1, 1],\n",
    "                \"datatype\": \"STRING\",\n",
    "                \"data\": data\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    response = requests.post(infer_url, json=json_data, verify=False)\n",
    "    response_dict = response.json()\n",
    "    return response_dict['outputs'][0]['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Getting the Prediction  \n",
    "\n",
    "Finally, we send the **Spotify ID** of our selected song to the model and obtain a **prediction**. In this step, the model processes the song's features and returns a prediction that reflects how it interprets the input data. \n",
    "\n",
    "The result we receive can then be used for tasks like generating recommendations or ranking songs. With this final step, we've successfully connected our **Feast-powered feature store** to a **machine learning model**, enabling real-time predictions! ðŸŽ¶ðŸš€\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data = favorite_song[\"spotify_id\"].values\n",
    "prediction = rest_request(data)\n",
    "prediction"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
