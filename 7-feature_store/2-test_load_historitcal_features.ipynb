{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfdf04eb",
   "metadata": {},
   "source": [
    "# Offline Features\n",
    "\n",
    "Now that we have applied our features, let's use them to grab a training dataset consisting of the features we just defined.  \n",
    "In this case we are fetching the full dataset with all the features, but as we will see in this notebook, it would be very simple to specify just a few features we wanted, take features from different FeatureViews, or a specific time-window that we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ba4341-f808-4667-bd7b-d9c3df00967b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import feast\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import psycopg2\n",
    "import yaml\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c48b7c0",
   "metadata": {},
   "source": [
    "Just like before, we use our yaml file to initialize our Feast python client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc950cb2-cf5f-4ee0-afde-60174dfd9ce5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('feature_repo/feature_store.yaml', 'r') as file:\n",
    "    fs_config_yaml = yaml.safe_load(file)\n",
    "\n",
    "fs_config = feast.repo_config.RepoConfig(**fs_config_yaml)\n",
    "fs = feast.FeatureStore(config=fs_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d4157e",
   "metadata": {},
   "source": [
    "### Point-in-time correctness\n",
    "To get datapoints from Feast, we have to provide it with the ID we want to get features for as well as a date.  \n",
    "Feast then finds the most recent feature values before that date for the selected features. This ensures that our models donâ€™t accidentally use future information, preventing data leakage.  \n",
    "\n",
    "In our case, we are using the song_rankings dataset to grab features from the song_properties data and merge them together.  \n",
    "Because we have multiple songs from the same date and with the same ID in the rankings dataset, we are also adding a small date delta to make sure the Feast doesn't discard any of the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e2088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = pd.read_parquet(\"../99-data_prep/song_rankings.parquet\")\n",
    "# Feast will remove rows with identical id and date so we add a small delta to each\n",
    "microsecond_deltas = np.arange(0, len(training_dataset))*2\n",
    "training_dataset['snapshot_date'] = training_dataset['snapshot_date'] + pd.to_timedelta(microsecond_deltas, unit='us')\n",
    "training_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5820f657",
   "metadata": {},
   "source": [
    "Now we can specify what features we want to get, note that we also say what Feature View those features come from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ce56f0-342a-4dbf-8bda-14922da87bde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features=[\n",
    "        \"song_properties:is_explicit\",\n",
    "        \"song_properties:duration_ms\",\n",
    "        \"song_properties:danceability\",\n",
    "        \"song_properties:energy\",\n",
    "        \"song_properties:key\",\n",
    "        \"song_properties:loudness\",\n",
    "        \"song_properties:mode\",\n",
    "        \"song_properties:speechiness\",\n",
    "        \"song_properties:acousticness\",\n",
    "        \"song_properties:instrumentalness\",\n",
    "        \"song_properties:liveness\",\n",
    "        \"song_properties:valence\",\n",
    "        \"song_properties:tempo\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61085d0",
   "metadata": {},
   "source": [
    "And finally we fetch the historical data which will be our training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25c7a97-0f10-453e-9a49-3d99144ca44f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_df = fs.get_historical_features(entity_df=training_dataset, features=features).to_df()\n",
    "training_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2d2449",
   "metadata": {},
   "source": [
    "We now know how to get training data from Feast, let's next look at how to use it during inference.  \n",
    "In the next notebook we will fetch Online Features: [3-test_load_online_features.ipynb](3-test_load_online_features.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
